# This resource defines the compute and orchestration logic for the clickstream ingestion.
# Managed via Databricks Asset Bundles (DABs) for version-controlled infrastructure.

resources:
  pipelines:
    # DATA ASSET: Defines the Medallion architecture and transformation logic.
    clickstream_pipeline:
      name: "[dev] Clickstream Pipeline"

      # RELEASE CHANNEL:
      # 'current' uses the GA version of DLT/Lakeflow. 
      # Ensures stability for production workloads.
      channel: current

      # EXECUTION STRATEGY: 
      # Continuous mode enables real-time ingestion with lower latency.
      continuous: true 

      # COMPUTE ARCHITECTURE:
      # Fully managed serverless compute eliminates manual cluster configuration.
      serverless: true

      # DATA GOVERNANCE:
      # Targets Unity Catalog for centralized lineage and RBAC.
      catalog: ${var.catalog}
      target: ${var.schema}

      # LOGIC ENCAPSULATION:
      # Pointer to the Spark Declarative Pipeline (SDP) transformation logic.
      libraries:
        - file:
            path: ../src/my_transformation.py

      # RUNTIME CONFIGURATION:
      configuration:
        # Source location for Auto Loader to monitor for new JSON events.
        pipeline.landing_path: ${var.landing_path}

  # ORCHESTRATION LAYER:
  # The Manager ensures the pipeline stays running and handles self-healing.
  jobs:
    clickstream_pipeline_manager:
      name: "[dev] Clickstream Pipeline Manager"

      tasks:
        - task_key: run_and_monitor_pipeline

          # RETRY LOGIC (Task Level):
          # Retries this task up to 3 times if it fails due to transient issues.
          max_retries: 3

          pipeline_task:
            pipeline_id: ${resources.pipelines.clickstream_pipeline.id}
